[project]
name = "nlp"
version = "0.1.0"
description = ""
authors = [{ name = "Tatsuki Okada", email = "tatsukio0522@gmali.com" }]
requires-python = ">=3.13"
dependencies = [
    "python-dotenv>=1.0.0",
    "setuptools>=80.9.0",
    "fire>=0.7.1",
    "pydantic>=2.12.4",
    "beautifulsoup4>=4.14.0",
    "selenium>=4.38.0",
    "playwright>=1.56.0",
    "fastapi>=0.121.0",
    "uvicorn>=0.38.0",
    "polars>=1.35.2",
    "pandas>=2.3.3",
    "openpyxl>=3.1.2",
    "matplotlib>=3.10.7",
    "seaborn>=0.13.2",
    "japanize-matplotlib>=1.1.3",
    "matplotlib-fontja>=1.1.0",
    "numpy>=2.3.4",
    "tqdm>=4.67.1",
    "scikit-learn>=1.7.2",
    "aiohttp>=3.9.5",
    "tenacity>=9.1.2",
    "toml>=0.10.2",
    "returns>=0.26.0",
    "cachetools>=6.2.1",
    "more-itertools>=10.8.0",
    "injector>=0.22.0",
    "dependency-injector>=4.48.2",
    "torch==2.8.0+cu128; sys_platform == 'linux' and platform_machine == 'x86_64'",
    "torch==2.8.0; sys_platform == 'darwin' or (sys_platform == 'linux' and platform_machine == 'aarch64')",
    "pytorch-lightning>=2.5.6",
    "transformers>=4.51.0",
    "sentence-transformers>=5.0.0",
    "accelerate>=1.11.0",
    "trl>=0.25.0",
    "datasets==3.6.0",
    "evaluate>=0.4.6",
    "hf-transfer>=0.1.9",
    "optimum>=1.13.2",
    "sentencepiece>=0.2.1",
    "protobuf>=3.20.1",
    "peft>=0.17.1",
    "spacy>=3.3.0",
    "litellm>=1.79.3",
    "langchain>=1.0.5",
    "google-adk>=1.18.0",
    "optuna>=4.5.0",
    "demoji>=1.1.0",
    "emoji>=1.7.0",
    "mojimoji>=0.0.12",
    "pillow>=12.0.0",
    "hatchling>=1.27.0",
    "editables>=0.5",
    "wheel>=0.45.1",
    "jsonlines>=4.0.0",
    "datasketch>=1.7.0",
    "gensim>=4.4.0",
    "bm25s>=0.2.14",
    "mecab-python3>=1.0.4",
    "unidic-lite>=1.0.8",
    "sudachipy>=0.6.10",
    "sudachidict-core>=20250129",
]

[tool.hatch.build.targets.wheel]
packages = ["src/nlp", "src"]

[tool.uv]
default-groups = ["dev"]
no-build-isolation-package = ["flash-attn"]

[[tool.uv.index]]
name = "torch-cuda"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name = "torch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.uv.sources]
torch = [
    { index = "torch-cuda", marker = "sys_platform == 'linux' and platform_machine == 'x86_64'" },
    { index = "torch-cpu", marker = "sys_platform == 'darwin' or (sys_platform == 'linux' and platform_machine == 'aarch64')" },
]

[tool.ruff]
target-version = "py313"
line-length = 119
indent-width = 4
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".git-rewrite",
    ".hg",
    ".ipynb_checkpoints",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pyenv",
    ".pytest_cache",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    ".vscode",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "site-packages",
    "venv",
]

[tool.ruff.lint]
select = ["ALL"]
ignore = [
    "D100",
    "D101",
    "D102",
    "D103",
    "D104",
    "D105",
    "D106",
    "D107",
    "D203",
    "D213",
    "G004",
    "Q000",
    "Q003",
    "EM101",
    "EM102",
    "COM812",
    "FBT001",
    "FBT002",
    "TRY003",
    "INP001",
]
fixable = ["ALL"]
unfixable = []

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = [
    "S101",
    "PLR2004",
]

[tool.ruff.lint.isort]
section-order = [
    "future",
    "standard-library",
    "third-party",
    "first-party",
    "local-folder",
]
split-on-trailing-comma = true

[tool.ruff.format]
quote-style = "single"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.mypy]
python_version="3.13"
files = "src"
ignore_missing_imports = true
disallow_untyped_defs = true
no_implicit_optional = true
allow_redefinition = false
show_error_codes = true
pretty = true

[tool.pytest.ini_options]
filterwarnings = ["ignore::DeprecationWarning",]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
    "tensorboard>=2.20.0",
    "wandb>=0.23.0",
    "jupyterlab>=4.1.0",
    "marimo>=0.17.0",
    "tox>=4.30.0",
    "pytest>=9.0.0",
    "pytest-xdist>=3.8.0",
    "pytest-asyncio>=1.3.0",
    "ruff>=0.14.4",
    "mypy>=1.18.0",
    "ty>=0.0.1a26",
    "nbstripout>=0.8.0",
    "pre-commit>=4.3.0",
    "types-pyyaml>=6.0.12.20250402",
    "types-toml>=0.10.8.20240310",
    "types-requests>=2.32.0.20241016",
]
cuda = [
    "flash-attn>=2.7.3",
    "triton>=3.4.0",
    "deepspeed>=0.17.0",
]
